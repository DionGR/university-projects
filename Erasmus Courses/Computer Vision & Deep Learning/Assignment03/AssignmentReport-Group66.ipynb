{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDT4265 - Computer Vision & Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3 Report - Group 66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dionysios Rigatos <br />\n",
    "> dionysir@stud.ntnu.no <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Τask 1a)\n",
    "\n",
    "Since the filter is not symmetric and we want to be performing convolution by hand, we will be rotating the kernel twice.\n",
    "\n",
    "Our new kernel is:\n",
    "```md\n",
    "1 0 -1\n",
    "2 0 -2\n",
    "1 0 -1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now perform convolution (only 1 page will be added here as reference for brevity):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![conv](./plots/conv_hand.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Τask 1b)\n",
    "\n",
    "The answer is (i), the Convolutional Layer. The reason is because in the convolutional layer, each specific kernel extracts a specific feature from each spot of the input image it is applied - and it is applied all over it. Thus, translational shifts do not affect the inference ability of the model as the feature will be extracted no matter where it is in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Τask 1c)\n",
    "\n",
    "We want our output to be $W \\times H \\times 6$. Since we have $F = 7$ and $S = 1$, we can use the formula (for both $H$ and $W$):\n",
    "\n",
    "* $H = (H_{in} - F + 2P)/S + 1 <=> HS - S = H_{in} - F + 2P \n",
    "\n",
    "    <=> P = (H_{in}S - H_{in} + F - S)/2$\n",
    "\n",
    "So:\n",
    "\n",
    "* $P = (1H_{in} - H_{in} + 7 - 1)/2 = (H_{in} - H_{in} + 6)/2 = 3$\n",
    "\n",
    "That applies for both $H$ and $W$, so the padding is $3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Τask 1d)\n",
    "\n",
    "Given $H_{in} = 512$, $W_{o} = H_{o} = 508$, $D = 12$, $S = 1$ and $P = 0$, we can use the formula:\n",
    "\n",
    "* $(H_{in} - F + 2P)/S + 1 = H_{o} <=> (512 - F + 0)/1 + 1 = 508 \n",
    "    \n",
    "    <=> 512 - F = 507 <=> F = 5$\n",
    "\n",
    "So the filter size is $5 \\times 5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Τask 1e)\n",
    "\n",
    "Given, for this layer, $H_{in} = 508$, $F = 2$ and $S = 2$, we can use the formula for pooling layers:\n",
    "\n",
    "* $H_{o} = (H_{in} - F)/S + 1 <=> (508 - 2)/2 + 1 = 254$\n",
    "\n",
    "Equally, $W_{o} = 254$.\n",
    "\n",
    "So the spatial dimensions of the pooled feature maps are $254 \\times 254$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Τask 1f)\n",
    "\n",
    "We now have $H_{in} = 254$, $F = 3$ and $S = 1$. Using the formula for the convolutional layer:\n",
    "\n",
    "* $H_{o} = (H_{in} - F + 2P)/S + 1 = (254 - 3 + 0)/1 + 1 = 252$\n",
    "\n",
    "Equally, $W_{o} = 252$.\n",
    "\n",
    "So the spatial dimensions of the output feature maps are $252 \\times 252$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Τask 1g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each layer, we have:\n",
    "\n",
    "1. $(5 \\times 5 \\times 3 + 1) \\times 32 = 2432$\n",
    "2. $(5 \\times 5 \\times 32 + 1) \\times 64 = 51264$\n",
    "3. $(5 \\times 5 \\times 64 + 1) \\times 128 = 204928$ \n",
    "4. Here, the spatial dimensions of the pooled feature map is $4 \\times 4$. So, the number of parameters is $(4 \\times 4 \\times 128 + 1) \\times 64 = 131136$\n",
    "5. $(64 + 1) \\times 10 = 650$\n",
    "\n",
    "So, the total number of parameters is $2432 + 51264 + 204928 + 131136 + 650 = 390410$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![task2img](plots/task2_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Training Accuracy**: 73.36%\n",
    "* **Validation Accuracy**: 69.3%\n",
    "* **Testing Accuracy**: 68.61%\n",
    "\n",
    "This took 9 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our over-75% model has the following structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```md\n",
    "ImprovedModel(\n",
    "  (feature_extractor): Sequential(\n",
    "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (1): PReLU(num_parameters=1)\n",
    "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (4): Dropout(p=0.2, inplace=False)\n",
    "    (5): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (6): PReLU(num_parameters=1)\n",
    "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (9): Dropout(p=0.2, inplace=False)\n",
    "    (10): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (11): PReLU(num_parameters=1)\n",
    "    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (14): Dropout(p=0.1, inplace=False)\n",
    "    (15): Flatten(start_dim=1, end_dim=-1)\n",
    "  )\n",
    "  (classifier): Sequential(\n",
    "    (0): Linear(in_features=2048, out_features=64, bias=True)\n",
    "    (1): PReLU(num_parameters=1)\n",
    "    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (3): Linear(in_features=64, out_features=10, bias=True)\n",
    "  )\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can replicate it by running the task3_train_75 notebook. A breakdown of what was used to reach this improvement in accuracy is described in the Task3 section - however a quick note is that the training hyperparameters were not altered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![task3b_img](./plots/task3_75_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Training Accuracy**: 81.8%\n",
    "* **Validation Accuracy**: 81.9%\n",
    "* **Testing Accuracy**: 76.77%\n",
    "\n",
    "This took 9 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What worked well:\n",
    " \n",
    "* **Data Augmentation** worked very well. We had to be careful so as to make sure we only augment the train data and not the validation/test data. The model is now able to generalize better as it is learning to distinguish more features in different conditions (i.e. noisy, rotated etc). Specifically:\n",
    "    * **RandomResizedCrop** was added, which only keeps a random part of the image as a training example.\n",
    "    * **ColorJitter** was added, which adds color noise in the image.\n",
    "* **Batch Normalization** helped make sure we converge earlier than usualy by smoothening out the gradient landscape, helping us stay in track with the task requirements. Note: We added BN for both feature extraction and FC inference.\n",
    "* **Dropout** reduced overfitting during training, as expected, as we are training an ensemble of models with different neurons activated. Only low dropout values seemed to work well - going over 0.3 resulted in a performance loss (probably because we dropped too many parts of features that were relevant).\n",
    "* **PReLU** activation slightly improved activation, acting as an improvement over LeakyReLU (which helps diminishing gradient), by having a learnable slope.\n",
    "* **Adam** optimizer slightly improved performance which is expected, as it utilizes adaptive momentum allowing us to converge into a solution much faster, and better minima. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did **not** work well:\n",
    "\n",
    "* **Decreasing Filters** lowered the accuracy as expected, as the model was not able to capture enough features off the images and thus not generalizing very well.\n",
    "* **Decreasing Filter Size** did not work very well either, probably because for this specific dataset, the features are in larger grids.\n",
    "* **Adjusting batch_size, learning_rate** did not help and the original values performed very well.\n",
    "* **L2 regularization** ontop of Dropout did not seem to have any effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The golden method seemed to be **Data Augmentation** in combination with Dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img_task3e](./plots/task3_80_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tis final improvement, here's what I did:\n",
    "\n",
    "* **Increase number of filters** to 64, which allowed for more features to be captured.\n",
    "\n",
    "* **Increasing amount of layers**, and specifically applying 2 convolutions before maxpooling as suggested (not replacing Maxpooling!), gave the final push to consistently surpassing 80% accuracy on the test set. More complex patterns are captured in the data and convergence now happens on less than 7-8 epochs! Applying a more sophisticated architecture did indeed help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Training Accuracy**: 90.0%\n",
    "* **Validation Accuracy**: 89.24%\n",
    "* **Testing Accuracy**: 84.18%\n",
    "\n",
    "This took 8 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems to overfit slightly seeing how the training/val accuracy are significantly higher than the testing accuracy. The resutls are still satisfactory, and regularizing further almost always led into the model not meeting the target for the test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img_task4](./plots/task4_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Training Accuracy**: 93.75%\n",
    "* **Validation Accuracy**: 94.54%\n",
    "* **Testing Accuracy**: 89.98%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters are as follows:\n",
    "* **Batch Size** of 32\n",
    "* **Learning Rate** of 5e10-4.\n",
    "* **Early Stop** count of 3.\n",
    "* **Data Augmentation** identical to Task3.\n",
    "* **Optimizer** Adam.\n",
    "\n",
    "and the original image size of 224x224.\n",
    "\n",
    "When training with the ResNet, we perform image normalization, as specified in the imagenet-normalization-implementation link, with values:\n",
    "* **Mean** of [0.485, 0.456, 0.406]\n",
    "* **Standard Deviation** of [0.229, 0.224, 0.225]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
